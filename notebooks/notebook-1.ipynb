{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/11/18 16:32:28 WARN Utils: Your hostname, abdou-Nitro-AN515-55 resolves to a loopback address: 127.0.1.1; using 10.188.49.204 instead (on interface wlp0s20f3)\n",
      "23/11/18 16:32:28 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/11/18 16:32:29 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "os.environ[\"PYSPARK_PYTHON\"] = sys.executable\n",
    "os.environ[\"PYSPARK_DRIVER_PYTHON\"] = sys.executable\n",
    "\n",
    "from pyspark import SparkContext, SparkConf\n",
    "\n",
    "#We can create a SparkConf() object and use it to initialize the spark context\n",
    "conf = SparkConf().setAppName(\"Notebook 1\").setMaster(\"local[4]\") #Initialize spark context using 4 local cores as workers\n",
    "sc = SparkContext(conf=conf)    \n",
    "\n",
    "from pyspark.rdd import RDD"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-18T15:32:26.874431358Z"
    }
   },
   "id": "initial_id"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Words Count on the Moby Dick text\n",
    "\n",
    "![MobyDick](https://d28hgpri8am2if.cloudfront.net/book_images/onix/cvr9781681778488/moby-dick-9781681778488_xlg.jpg)\n",
    "\n",
    "And so begins an incredible odyssey that will take ship, sailors and readers to the edge of darkness. Moby Dick\" is an epic tragedy of terrible dramatic power, the endless, desperate quest of the captain of a drunken ship on a voyage of no return."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "efe07bf00aa931fc"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 1.75 ms, total: 1.75 ms\n",
      "Wall time: 45.6 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": "pyspark.rdd.RDD"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "text_file = sc.textFile(\"../data/mobydick.txt\")\n",
    "type(text_file)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-18T15:44:07.955015759Z",
     "start_time": "2023-11-18T15:44:07.895604162Z"
    }
   },
   "id": "edf7fbaceb43100"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.26 ms, sys: 103 µs, total: 1.37 ms\n",
      "Wall time: 931 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "words = text_file.flatMap(lambda line: line.split(\" \"))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-18T15:44:10.846441360Z",
     "start_time": "2023-11-18T15:44:10.840409005Z"
    }
   },
   "id": "b056a230a64170e6"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 28 µs, sys: 2 µs, total: 30 µs\n",
      "Wall time: 33.4 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "not_empty = words.filter(lambda x: x!=\"\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-18T15:44:11.457811575Z",
     "start_time": "2023-11-18T15:44:11.451017374Z"
    }
   },
   "id": "d082b343cc0a7cc"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.72 ms, sys: 0 ns, total: 7.72 ms\n",
      "Wall time: 50.8 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "key_val = not_empty.map(lambda x: (x, 1))\n",
    "counts= key_val.reduceByKey(lambda x1, x2: x1+x2)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-18T15:44:12.028598855Z",
     "start_time": "2023-11-18T15:44:11.971314391Z"
    }
   },
   "id": "1ea463618f5ffb9c"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of different words = 19840 number of words = 115314 nb of occurence per word = 5.81\n",
      "CPU times: user 7.52 ms, sys: 0 ns, total: 7.52 ms\n",
      "Wall time: 205 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "## get the number of different words\n",
    "diff_words = counts.count()\n",
    "## get the number of words\n",
    "nb_words = counts.map(lambda x: x[1]).reduce(lambda x, y: x+y)\n",
    "\n",
    "print(f\"number of different words = {diff_words} number of words = {nb_words} nb of occurence per word = {round(nb_words / diff_words, 2)}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-18T16:02:19.461115873Z",
     "start_time": "2023-11-18T16:02:19.238145460Z"
    }
   },
   "id": "f353676b64e9d67d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### To sum up\n",
    "\n",
    "- An RDD is a distributed immutable array and is the core data structure of Spark\n",
    "- It is not possible to operate on RDD directly but through **Transformations** and **Actions**\n",
    "- **Transformations** transform an RDD into another RDD\n",
    "- **Actions** output their results on the head node\n",
    "- After the action is done you are now using the head node and no longer on the workers node.\n",
    "- RDD operations (**Transformations** and **Actions**) are added to what we call an **Execution Plan**\n",
    "- The plan is executed when the result is needed\n",
    "- It is possible to store intermediate result explicitly by using caching"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2b57bccc91e0a596"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "51851e17982c4f6"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
